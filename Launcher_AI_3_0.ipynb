{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgN2Z4MlyzrNsrkmtI80AR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdce252e"
      },
      "source": [
        "### Cella 0: stato iniziale\n",
        "\n",
        "Questa cella stampa la versione di Python e di tutte le librerie in uso nell'ambiente Colab, quindi effettua un chek di compatibilit√† librerie. Questo √® utile per la risoluzione dei problemi di dipendenza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab99f58f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d3fd957-c5d4-435b-c634-e47ced1df175"
      },
      "source": [
        "from pathlib import Path\n",
        "import os, sys\n",
        "import shutil\n",
        "print(\"Versione del file 0.3.0, pushata in github\")\n",
        "print(sys.version)\n",
        "print(f\"PATH (Eseguibili):\\n {os.environ['PATH']}\")\n",
        "print(f\"sys.path (Librerie Python):\\n {sys.path}\")\n",
        "# !pip list # decommentare per leggere l'elenco di librerie preinstallate\n",
        "# in caso di anomalia del seguente check\n",
        "!pip check\n",
        "\n",
        "# ==============================================================================\n",
        "# Fase 1: RILEVAZIONE AMBIENTE E SETTAGGIO BRANCH\n",
        "# ==============================================================================\n",
        "# E' la primissima fase, non ne posso fare un moduio da scaricare da github\n",
        "# 1.1 Logica di rilevazione\n",
        "if Path(\"/content\").exists():\n",
        "    ENV = \"COLAB\"\n",
        "    ROOT = Path(\"/content\")\n",
        "    BRANCH = \"sviluppo\"\n",
        "elif Path(\"/home/studio-lab-user\").exists():\n",
        "    ENV = \"SAGEMAKER\"\n",
        "    ROOT = Path(\"/home/studio-lab-user\")\n",
        "#   BRANCH = \"main\" da ripristinare quando collaudato\n",
        "    BRANCH = \"sviluppo\"\n",
        "else:\n",
        "    ENV = \"UNKNOWN\"\n",
        "    ROOT = Path(os.getcwd())\n",
        "    BRANCH = \"main\"\n",
        "    print(\"‚ö†Ô∏è Non sei nella Root di un ambiente conosciuto.\")\n",
        "\n",
        "# 1.1.1 Variabili derivate\n",
        "# Usiamo 'repo' e 'modules' come nomi standard per facilitare la gestione delle celle future.\n",
        "REPO_LOCAL = ROOT / \"repo\"        # Dove scaricheremo tutto il repository\n",
        "TARGET_MODULES = ROOT / \"modules\"    # Dove copieremo i moduli per Python\n",
        "REPO_URL   = \"https://github.com/Theridel/Coach_2.0.git\"\n",
        "\n",
        "# 1.2 Output unico di riepilogo\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"üåç AMBIENTE : {ENV}\")\n",
        "print(f\"üåø BRANCH   : {BRANCH}\")\n",
        "print(f\"üìÅ ROOT     : {ROOT}\")\n",
        "print(f\"üìÇ REPO     : {REPO_LOCAL}\")\n",
        "print(f\"üìÇ MODULES  : {TARGET_MODULES}\")\n",
        "print(f\"{'='*40}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "PATH (Eseguibili):\n",
            " /opt/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "sys.path (Librerie Python):\n",
            " ['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython']\n",
            "ipython 7.34.0 requires jedi, which is not installed.\n",
            "========================================\n",
            "üåç AMBIENTE : COLAB\n",
            "üåø BRANCH   : sviluppo\n",
            "üìÅ ROOT     : /content\n",
            "üìÇ REPO     : /content/repo\n",
            "üìÇ MODULES  : /content/modules\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 1: Scarica il repository da github e Installazione delle dipendenze\n",
        "\n",
        "1. **Scaricamento del repository**: tutto il repository viene copiato nella directory /content/repo. Da questo, copiamo il contenuto di /runtime su /content\n",
        "2. **Installazione di varie librerie da requirements.txt**: Vengono installate librerie essenziali come `llama-cpp-python`, per l'interazione con i modelli GGUF (come Gemma). L'opzione `--upgrade` assicura di avere l'ultima versione e `-q` la rende silenziosa."
      ],
      "metadata": {
        "id": "dcuU0t1CqnAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 1\n",
        "\n",
        "# ==============================================================================\n",
        "# Fase 2: Scarica il repository da github\n",
        "# ==============================================================================\n",
        "# Ugualmente, non pu√≤ far parte di un modulo\n",
        "# 2.1 Pulizia della directory (Strategica per Colab e SageMaker)\n",
        "if ENV == \"COLAB\":\n",
        "    print(f\"[CLEAN] Pulizia totale Colab (eccetto Drive)...\")\n",
        "    for item in ROOT.iterdir():\n",
        "        if item.name == \"drive\":\n",
        "            continue\n",
        "        try:\n",
        "            if item.is_dir():\n",
        "                shutil.rmtree(item)\n",
        "            else:\n",
        "                item.unlink()\n",
        "        except Exception as e:\n",
        "            print(f\"Errore: {e}\")\n",
        "\n",
        "elif ENV == \"SAGEMAKER\":\n",
        "    print(f\"[CLEAN] SageMaker: Pulizia selettiva per evitare accumulo residui...\")\n",
        "    # Definiamo cosa vogliamo che sia SEMPRE pulito prima di un nuovo \"travaso\"\n",
        "    pulizia_target = [REPO_LOCAL, TARGET_MODULES]\n",
        "\n",
        "    for cartella in pulizia_target:\n",
        "        if cartella.exists():\n",
        "            print(f\"   - Rimozione residui: {cartella.name}\")\n",
        "            shutil.rmtree(cartella)\n",
        "\n",
        "print(f\"[INFO] Pronto per Fase 2 (Clone) su {REPO_LOCAL}\")\n",
        "\n",
        "# 2.2: Clone del repository Git.\n",
        "# Esegue un 'git clone' per scaricare il repository per la prima volta.\n",
        "print(\"[PACK] Clono il repo...\")\n",
        "os.system(f\"git clone -b {BRANCH} {REPO_URL} {REPO_LOCAL}\") # Clona il repo usando os.system\n",
        "\n",
        "# 2.3: Copia del contenuto del repository in ROOT/{REPO_URL}/modules in ROOT/modules\n",
        "# La variabile 'src' punta alla directory /repo all'interno del repository clonato.\n",
        "src = REPO_LOCAL  # Puntiamo direttamente alla cartella principale del repo\n",
        "\n",
        "# Viene eseguito un controllo per assicurarsi che la cartella /repo esista.\n",
        "# Ogni elemento (file o directory) all'interno di 'runtime' viene copiato direttamente in /content/.\n",
        "# Se √® una directory, usa shutil.copytree; altrimenti, usa shutil.copy2 per i file.\n",
        "\n",
        "for item in src.iterdir():\n",
        "    if item.name == \".git\": continue # <--- Aggiungi questa riga\n",
        "    target = ROOT / item.name\n",
        "    if item.is_dir(): # <--- Deve essere allineato sotto 'target'\n",
        "        if target.exists():\n",
        "            shutil.rmtree(target)\n",
        "        shutil.copytree(item, target)\n",
        "    else:\n",
        "        shutil.copy2(item, target) # <--- Ricordati di aggiungere questo per i file singoli!\n",
        "\n",
        "print(f\"[PACK] Copia completata: {REPO_LOCAL.name}/* ‚Üí {ROOT}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Fase 3: Installa le librerie e le dipendenze\n",
        "# ==============================================================================\n",
        "\n",
        "# Fase 4. Installa le librerie necessarie\n",
        "!pip install -r {REPO_LOCAL}/requirements.txt -q --upgrade\n",
        "print(\"Dipendenze installate da requirements.txt.\")\n",
        "\n",
        "!pip install -r {REPO_LOCAL}/requirements_AI.txt -q --upgrade\n",
        "print(\"Dipendenze installate da requirements_AI.txt.\")\n",
        "\n",
        "\n",
        "# 3.1: COPIA SELETTIVA DELLA DIRECTORY /modules\n",
        "\n",
        "# Definiamo sorgente e destinazione per i moduli\n",
        "SORGENTE_MODULES = REPO_LOCAL / \"modules\"\n",
        "# TARGET_MODULES √® gi√† definita come ROOT / \"modules\" nella tua Fase 1.1.1\n",
        "\n",
        "if SORGENTE_MODULES.exists() and SORGENTE_MODULES.is_dir():\n",
        "    print(f\"[PACK] Sincronizzazione moduli: {SORGENTE_MODULES} ‚Üí {TARGET_MODULES}\")\n",
        "\n",
        "    # Se la cartella di destinazione esiste gi√†, la rimuoviamo per garantire una copia pulita\n",
        "    if TARGET_MODULES.exists():\n",
        "        shutil.rmtree(TARGET_MODULES)\n",
        "\n",
        "    # Copia ricorsiva di tutta la struttura (file .py, __init__.py e sottocartelle)\n",
        "    shutil.copytree(SORGENTE_MODULES, TARGET_MODULES)\n",
        "\n",
        "    # Aggiunta al path di sistema per permettere l'import immediato\n",
        "    if str(TARGET_MODULES) not in sys.path:\n",
        "        sys.path.append(str(TARGET_MODULES))\n",
        "        print(f\"‚úÖ Moduli pronti per l'import e aggiunti al sys.path\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Attenzione: La directory /modules non √® stata trovata nel repository clonato.\")\n",
        "\n",
        "print(\"Pronto per SETUP (cella 2). Puoi controllare il download con la cella Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCxG1C7ot5aa",
        "outputId": "f39620bb-d3b4-4b77-996d-61323dcfc128",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLEAN] Pulizia totale Colab (eccetto Drive)...\n",
            "[INFO] Pronto per Fase 2 (Clone) su /content/repo\n",
            "[PACK] Clono il repo...\n",
            "[PACK] Copia completata: repo/* ‚Üí /content\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDipendenze installate da requirements.txt.\n",
            "Dipendenze installate da requirements_AI.txt.\n",
            "[PACK] Sincronizzazione moduli: /content/repo/modules ‚Üí /content/modules\n",
            "Pronto per SETUP (cella 2). Puoi controllare il download con la cella Test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importo modulo"
      ],
      "metadata": {
        "id": "hXttFAIG5H8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from modules.envir_manager import get_env_context\n",
        "\n",
        "# 1. Recupero dei dati dal modulo\n",
        "ambiente = get_env_context()\n",
        "\n",
        "# 2. Stampa di prova nel main per verifica visiva (come richiesto)\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"VERIFICA AMBIENTE:\")\n",
        "for chiave, valore in ambiente.items():\n",
        "    print(f\"{chiave:15} : {valore}\")\n",
        "print(f\"{'='*40}\")\n",
        "\n",
        "# 3. Da qui in poi usi solo il dizionario ambiente\n",
        "# Esempio: os.chdir(ambiente['ROOT']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQhCpwVt2Etf",
        "outputId": "252f34b2-9883-4407-9731-3f8a07d7ba95",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "VERIFICA AMBIENTE:\n",
            "ENV             : COLAB\n",
            "ROOT            : /content\n",
            "BRANCH          : sviluppo\n",
            "REPO_LOCAL      : /content/repo\n",
            "TARGET_MODULES  : /content/modules\n",
            "PATH_DB         : /content/agent_instructions.db\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1gw5f7Jlrha"
      },
      "source": [
        "### Cella 2: Setup\n",
        "Questa celle si occupano della configurazione iniziale dell'ambiente.\n",
        "la prossima cella prepara SQLite da script, quella seguente lo fa da modulo, scegline una.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile modules/db_sqlite.py\n",
        "import sqlite3\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "def setup(ctx):\n",
        "    \"\"\"Configura l'ambiente SQLite e crea lo schema a 3 livelli.\"\"\"\n",
        "    nome_db = \"agent_instructions.db\"\n",
        "    path_lavoro = ctx['ROOT'] / nome_db\n",
        "    source_db = None\n",
        "\n",
        "    # 1. Ricerca Sorgente (Colab Drive -> Repo)\n",
        "    if ctx['ENV'] == \"COLAB\":\n",
        "        path_drive = Path(\"/content/drive/MyDrive/LLM Database\") / nome_db\n",
        "        if path_drive.exists():\n",
        "            source_db = path_drive\n",
        "\n",
        "    if not source_db:\n",
        "        path_repo = ctx['REPO_LOCAL'] / nome_db\n",
        "        if path_repo.exists():\n",
        "            source_db = path_repo\n",
        "\n",
        "    # 2. Copia o Inizializzazione\n",
        "    if source_db:\n",
        "        shutil.copy2(source_db, path_lavoro)\n",
        "    else:\n",
        "        conn = sqlite3.connect(path_lavoro)\n",
        "        _create_schema(conn)\n",
        "        conn.close()\n",
        "\n",
        "    return path_lavoro\n",
        "\n",
        "def _create_schema(conn):\n",
        "    \"\"\"Crea le tabelle per la gestione della memoria.\"\"\"\n",
        "    cursor = conn.cursor()\n",
        "    # Memoria Breve (ultimi scambi)\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS short_term_memory (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            role TEXT,\n",
        "            content TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    # Memoria Media (riassunti sessione)\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS session_summary (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "            summary_text TEXT,\n",
        "            last_message_id INTEGER\n",
        "        )\n",
        "    \"\"\")\n",
        "    # Variabili di Stato\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS session_context (\n",
        "            key TEXT PRIMARY KEY,\n",
        "            value TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "def get_chat_history(path_db, limit=10):\n",
        "    \"\"\"Recupera gli ultimi scambi per il prompt.\"\"\"\n",
        "    conn = sqlite3.connect(path_db)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT role, content FROM short_term_memory ORDER BY id DESC LIMIT ?\", (limit,))\n",
        "    history = cursor.fetchall()\n",
        "    conn.close()\n",
        "    # Ribaltiamo per avere l'ordine cronologico corretto\n",
        "    return history[::-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4YhKp_HVCxl",
        "outputId": "70793881-248d-4119-c83b-010725b2e578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing modules/db_sqlite.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Aggiungiamo la ROOT al path di sistema se non c'√® gi√†\n",
        "# Questo serve a Python per \"vedere\" la cartella modules\n",
        "if str(ambiente['ROOT']) not in sys.path:\n",
        "    sys.path.append(str(ambiente['ROOT']))\n",
        "\n",
        "# 2. Import del modulo\n",
        "try:\n",
        "    import modules.db_sqlite as db_local\n",
        "    print(\"‚úÖ Modulo 'db_sqlite' importato con successo.\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Errore nell'importazione del modulo: {e}\")\n",
        "\n",
        "# 3. Inizializzazione pratica\n",
        "# Questa riga esegue tutto: cerca il DB, lo copia in locale e crea le tabelle\n",
        "path_db = db_local.setup(ambiente)\n",
        "\n",
        "print(f\"üìç Database operativo in: {path_db}\")\n",
        "\n",
        "# 4. Test rapido di lettura tabelle\n",
        "import sqlite3\n",
        "conn = sqlite3.connect(path_db)\n",
        "tabelle = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
        "conn.close()\n",
        "print(f\"üìä Tabelle confermate: {[t[0] for t in tabelle]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA9wY-sZjZPN",
        "outputId": "1a91ea28-2f5b-464d-aa3c-7b8e33fb60c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Modulo 'db_sqlite' importato con successo.\n",
            "üìç Database operativo in: /content/agent_instructions.db\n",
            "üìä Tabelle confermate: ['instructions', 'sqlite_sequence']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Montaggio di Google Drive**: Viene montato Google Drive nel file system di Colab. Questo √® fondamentale per poter accedere ai modelli GGUF salvati.\n",
        "2. **Gestione errori**: avvisa in caso di fallimento del montaggio."
      ],
      "metadata": {
        "id": "IXSy3m5SjlAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 2b: Setup (Versione con Secrets)\n",
        "\n",
        "# 1. Importa librerie e moduli\n",
        "# Importazione diretta: se fallisce, controlla la Fase 4 della Cella 1\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import userdata  # Necessario per i Secrets\n",
        "from datetime import datetime\n",
        "from supabase import create_client, Client\n",
        "\n",
        "# 2. Monta Google Drive\n",
        "print(\"--- 1. Monta Google Drive ---\")\n",
        "if not os.path.exists('/content/drive'):\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"‚úÖ Google Drive montato con successo.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRORE: Impossibile montare Google Drive. {e}\")\n",
        "\n",
        "# --- CONFIGURAZIONE SUPABASE (SICURA) ---\n",
        "# Recupero dai Secrets di Colab.\n",
        "# Nota: In un ambiente locale potresti usare un file .env per gestire queste variabili.\n",
        "try:\n",
        "    SUPABASE_URL = userdata.get('SUPABASE_URL')\n",
        "    SUPABASE_ANON_KEY = userdata.get('SUPABASE_ANON_KEY')\n",
        "    print(\"üîë Chiavi caricate dai Secrets di Colab.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore nel caricamento dei Secrets: {e}\")\n",
        "    print(\"Assicurati di aver aggiunto SUPABASE_URL e SUPABASE_ANON_KEY nel pannello Secrets.\")\n",
        "\n",
        "# --- CONFIGURAZIONE PERCORSI SQLITE ---\n",
        "# NOME_DB = \"agent_instructions.db\"\n",
        "# CARTELLA_DRIVE = \"/content/drive/MyDrive/LLM Database/\"\n",
        "# PATH_REPO = f\"/content/repo/{NOME_DB}\"\n",
        "# PATH_DRIVE = os.path.join(CARTELLA_DRIVE, NOME_DB)\n",
        "# PATH_LAVORO = f\"/content/{NOME_DB}\"\n",
        "\n",
        "def setup_ambiente():\n",
        "    # --- Inizializzazione Supabase (Corretta) ---\n",
        "    global supabase\n",
        "    try:\n",
        "        supabase = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)\n",
        "        print(\"‚úÖ Connessione a Supabase stabilita.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Errore connessione Supabase: {e}\")\n",
        "\n",
        "# --- Gestione SQLite (Tua logica originale) ---\n",
        "#   os.makedirs(CARTELLA_DRIVE, exist_ok=True)\n",
        "#   esiste_drive = os.path.exists(PATH_DRIVE)\n",
        "#    esiste_repo = os.path.exists(PATH_REPO)\n",
        "#\n",
        "#    if esiste_drive:\n",
        "#        print(f\"üì• Trovato database su Drive. Caricamento in corso...\")\n",
        "#        shutil.copy2(PATH_DRIVE, PATH_LAVORO)\n",
        "#    elif esiste_repo:\n",
        "#        print(f\"üì¶ Drive vuoto. Caricamento dal Repo GitHub...\")\n",
        "#        shutil.copy2(PATH_REPO, PATH_LAVORO)\n",
        "#    else:\n",
        "#        print(\"üÜï Nessun database SQLite trovato. Ne verr√† creato uno nuovo.\")[]\n",
        "#\n",
        "#    if esiste_drive and esiste_repo:\n",
        "#        mtime_drive = os.path.getmtime(PATH_DRIVE)\n",
        "#        mtime_repo = os.path.getmtime(PATH_REPO)\n",
        "#        if abs(mtime_drive - mtime_repo) > 2:\n",
        "#            print(f\"‚ö†Ô∏è AVVISO: Differenza tra Drive e Repo rilevata.\")\n",
        "#\n",
        "#    print(f\"‚úÖ Ambiente pronto. File di lavoro locale: {PATH_LAVORO}\")\n",
        "\n",
        "setup_ambiente()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92eJwyHz0sMM",
        "outputId": "9e88eef4-d3aa-4830-e0f4-60a9ac48f314",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. Monta Google Drive ---\n",
            "üîë Chiavi caricate dai Secrets di Colab.\n",
            "‚úÖ Connessione a Supabase stabilita.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella test: verifichiamo lo scaricamento del repository"
      ],
      "metadata": {
        "id": "XRVwyPUVy3Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cella test b\n",
        "from pathlib import Path\n",
        "\n",
        "# Utilizziamo ctx['ROOT'] se gi√† definito, altrimenti fallback su /content\n",
        "content_path = ambiente.get('ROOT', Path('/content'))\n",
        "\n",
        "print(f\"üìä ISPEZIONE FILESYSTEM: {content_path}\")\n",
        "print(f\"{'-'*45}\")\n",
        "\n",
        "# Itera sugli elementi nella root\n",
        "for item in sorted(content_path.iterdir()):\n",
        "    # Esclusione specifica per il repo (troppo vasto da listare)\n",
        "    if item.is_dir() and item.name == \"repo\":\n",
        "        print(f\"üìÅ {item.name}/ [Directory Repo - Contenuto Nascosto]\")\n",
        "        continue\n",
        "\n",
        "    # Gestione Cartelle\n",
        "    if item.is_dir():\n",
        "        print(f\"üìÅ {item.name}/\")\n",
        "        sub_items = sorted(list(item.iterdir()))\n",
        "        if not sub_items:\n",
        "            print(\"    ‚îî‚îÄ‚îÄ (vuota)\")\n",
        "        else:\n",
        "            for sub_item in sub_items:\n",
        "                # Mostriamo solo i file o le sottocartelle immediate\n",
        "                prefisso = \"    ‚îú‚îÄ‚îÄ\" if sub_item != sub_items[-1] else \"    ‚îî‚îÄ‚îÄ\"\n",
        "                tipo = \"üìÅ \" if sub_item.is_dir() else \"üìÑ \"\n",
        "                print(f\"{prefisso} {tipo}{sub_item.name}\")\n",
        "\n",
        "    # Gestione File nella Root\n",
        "    elif item.is_file():\n",
        "        print(f\"üìÑ {item.name}\")\n",
        "\n",
        "print(f\"{'-'*45}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGxBixPM9wuJ",
        "outputId": "a3899686-7871-451e-b9ab-b43f29781acc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä ISPEZIONE FILESYSTEM: /content\n",
            "---------------------------------------------\n",
            "üìÑ .gitignore\n",
            "üìÑ LICENSE\n",
            "üìÑ Launcher_AI.ipynb\n",
            "üìÑ PROFILE.md\n",
            "üìÑ README.md\n",
            "üìÑ agent_instructions.db\n",
            "üìÅ app/\n",
            "    ‚îú‚îÄ‚îÄ üìÅ api\n",
            "    ‚îú‚îÄ‚îÄ üìÅ css\n",
            "    ‚îú‚îÄ‚îÄ üìÑ index.html\n",
            "    ‚îú‚îÄ‚îÄ üìÑ interfacciaAgent.html\n",
            "    ‚îú‚îÄ‚îÄ üìÑ package.json\n",
            "    ‚îú‚îÄ‚îÄ üìÅ scripts\n",
            "    ‚îî‚îÄ‚îÄ üìÑ vercel.json\n",
            "üìÅ drive/\n",
            "    ‚îú‚îÄ‚îÄ üìÅ .Encrypted\n",
            "    ‚îú‚îÄ‚îÄ üìÅ .Trash-0\n",
            "    ‚îú‚îÄ‚îÄ üìÅ .shortcut-targets-by-id\n",
            "    ‚îî‚îÄ‚îÄ üìÅ MyDrive\n",
            "üìÑ istruzioni_personalizzate.txt\n",
            "üìÅ modules/\n",
            "    ‚îú‚îÄ‚îÄ üìÑ __init__.py\n",
            "    ‚îú‚îÄ‚îÄ üìÅ __pycache__\n",
            "    ‚îú‚îÄ‚îÄ üìÑ db_sqlite.py\n",
            "    ‚îî‚îÄ‚îÄ üìÑ envir_manager.py\n",
            "üìÅ repo/ [Directory Repo - Contenuto Nascosto]\n",
            "üìÑ requirements.txt\n",
            "üìÑ requirements_AI.txt\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test di supabase"
      ],
      "metadata": {
        "id": "lqCiFkvYy8sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test  di Supabase\n",
        "# lettura Direttive AI\n",
        "\n",
        "def carica_direttive(progetto=\"AI-Agent\"):\n",
        "    try:\n",
        "        # Interroga Supabase filtrando per il tuo progetto\n",
        "        response = supabase.table(\"direttive_ai\").select(\"*\").eq(\"progetto_nome\", progetto).execute()\n",
        "\n",
        "        if response.data:\n",
        "            print(f\"--- Direttive caricate per il progetto: {progetto} ---\")\n",
        "            for record in response.data:\n",
        "                print(f\"[{record['sezione']}]: {record['contenuto']}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Nessuna direttiva trovata per questo progetto.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Errore durante la lettura: {e}\")\n",
        "\n",
        "# Esegui il test\n",
        "carica_direttive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2GLY5rCy_v7",
        "outputId": "c7071a1d-a64b-4b5b-9ade-906b76bb1a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Direttive caricate per il progetto: AI-Agent ---\n",
            "[Identit√†]: Durante la conversazione, chiamami Theridel, tu sarai Bot AI.\n",
            "Mi fornirai tanto supporto allo sviluppo dell'AI Agent con Gemma, Colab e Supabase.\n",
            "Mio figlio √® tosto. Anche l'altro lo √®..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3fe3a84"
      },
      "source": [
        "### 3. Gestione delle Istruzioni tramite Database SQLite\n",
        "\n",
        "Per scenari pi√π complessi, dove le istruzioni sono molteplici, dinamiche o devono essere associate a specifici contesti/tool, un database offre maggiore flessibilit√† e organizzazione rispetto a semplici file di testo. Qui useremo **SQLite**, un database leggero e basato su file, ideale per iniziare in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84523ea3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bd834e-0a5a-4504-96d2-aa331fdc51e1",
        "collapsed": true
      },
      "source": [
        "# Cella 3: SQLite Operazioni e Backup\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "# Nota: PATH_LAVORO e PATH_DRIVE sono ereditati dalla cella precedente\n",
        "\n",
        "print(\"--- 2. Esecuzione Operazioni Database ---\")\n",
        "\n",
        "def gestisci_database():\n",
        "    # 1. Connessione al database LOCALE (veloce e sicuro)\n",
        "    try:\n",
        "        conn = sqlite3.connect(PATH_LAVORO)\n",
        "        cursor = conn.cursor()\n",
        "        print(f\"‚úÖ Connesso al DB locale: {NOME_DB}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRORE Connessione: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # 2. Creazione Tabella (Schema)\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS instructions (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                name TEXT NOT NULL UNIQUE,\n",
        "                content TEXT NOT NULL,\n",
        "                description TEXT\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # 3. Inserimento Dati (Logica upsert/ignore)\n",
        "        istruzioni_da_inserire = [\n",
        "            ('persona_base', 'Sei un assistente AI neutrale e collaborativo. Rispondi sempre in italiano.', 'Prompt base'),\n",
        "            ('formato_codice', 'Presenta sempre il codice formattato correttamente.', 'Formattazione'),\n",
        "            ('evita_saluti', 'Evita saluti, vai dritto al punto.', 'Stile')\n",
        "        ]\n",
        "\n",
        "        changes_count = 0\n",
        "        for name, content, desc in istruzioni_da_inserire:\n",
        "            try:\n",
        "                # Usiamo INSERT OR IGNORE o gestiamo l'errore per evitare duplicati\n",
        "                cursor.execute(\"INSERT INTO instructions (name, content, description) VALUES (?, ?, ?)\",\n",
        "                               (name, content, desc))\n",
        "                print(f\"   ‚ûï Istruzione inserita: '{name}'\")\n",
        "                changes_count += 1\n",
        "            except sqlite3.IntegrityError:\n",
        "                # Se esiste gi√†, possiamo decidere se ignorare o aggiornare. Qui ignoriamo e avvisiamo.\n",
        "                # Se volessi aggiornare useresti: UPDATE instructions SET content = ? WHERE name = ?\n",
        "                pass\n",
        "                # print(f\"   (i) Istruzione '{name}' gi√† presente.\")\n",
        "\n",
        "        conn.commit()\n",
        "        print(f\"‚úÖ Modifiche salvate in locale ({changes_count} nuovi inserimenti).\")\n",
        "\n",
        "        # 4. Lettura e Controllo\n",
        "        print(\"\\n--- Anteprima Contenuto DB ---\")\n",
        "        df = pd.read_sql_query(\"SELECT name, description FROM instructions\", conn)\n",
        "        print(df)\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRORE durante le query: {e}\")\n",
        "        conn.rollback()\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "    # 5. SALVATAGGIO SU DRIVE (Cruciale)\n",
        "    # Sovrascriviamo il file su Drive con la versione appena modificata\n",
        "    try:\n",
        "        shutil.copy2(PATH_LAVORO, PATH_DRIVE)\n",
        "        print(f\"\\nüíæ BACKUP RIUSCITO: Database salvato su Google Drive.\")\n",
        "        print(f\"   Percorso: {PATH_DRIVE}\")\n",
        "        print(f\"   Ora: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERRORE BACKUP SU DRIVE: {e}\")\n",
        "        print(\"‚ö†Ô∏è Attenzione: i dati sono salvati solo nell'ambiente temporaneo di Colab!\")\n",
        "\n",
        "# Eseguiamo la funzione\n",
        "gestisci_database()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Esecuzione Operazioni Database ---\n",
            "‚úÖ Connesso al DB locale: agent_instructions.db\n",
            "‚úÖ Modifiche salvate in locale (0 nuovi inserimenti).\n",
            "\n",
            "--- Anteprima Contenuto DB ---\n",
            "             name    description\n",
            "0    persona_base    Prompt base\n",
            "1  formato_codice  Formattazione\n",
            "2    evita_saluti          Stile\n",
            "------------------------------\n",
            "\n",
            "üíæ BACKUP RIUSCITO: Database salvato su Google Drive.\n",
            "   Percorso: /content/drive/MyDrive/LLM Database/agent_instructions.db\n",
            "   Ora: 04:58:41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 4: Caricamento e Inizializzazione del Modello LLM\n",
        "\n",
        "Questa cella √® dedicata alla fase di caricamento e inizializzazione del modello di linguaggio (LLM) Gemma.\n",
        "\n",
        "1.  **Istanziazione:** La libreria `llama_cpp` viene impiegata per creare un'istanza dell'oggetto `Llama`.\n",
        "2.  **Localizzazione Risorsa:** Si definisce il percorso su Google Drive (`CARTELLA_MODELLI`) dove risiede il file del modello (`.gguf`).\n",
        "3.  **Ottimizzazione Hardware:** Il parametro `n_gpu_layers=-1` configura il modello per delegare la massima parte dei calcoli alla GPU, incrementando le prestazioni.\n",
        "4.  **Gestione Contesto:** `n_ctx` imposta la finestra di contesto, cio√® la quantit√† di testo che il modello pu√≤ \"ricordare\" per generare risposte coerenti.\n",
        "\n",
        "**Verifica Esito:** Un caricamento successo √® attestato da un messaggio di conferma. Eventuali errori indicano problemi di percorso o compatibilit√†, impedendo l'operativit√† del sistema AI.\n"
      ],
      "metadata": {
        "id": "JlInYn_zi1P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 4: Definizione Percorso e Caricamento del Modello\n",
        "print(\"--- 2. Caricamento Modello ---\")\n",
        "\n",
        "# 1. Creazione istanza Llama\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# 2. Definizione percorso modelli su Drive\n",
        "CARTELLA_MODELLI = \"/content/drive/MyDrive/LLM Models/\"\n",
        "NOME_FILE_GGUF = \"gemma-2-2b-it-Q8_0.gguf\"\n",
        "PERCORSO_MODELLO_COMPLETO = os.path.join(CARTELLA_MODELLI, NOME_FILE_GGUF)\n",
        "\n",
        "llm = None # Inizializza la variabile llm\n",
        "\n",
        "# Verifica l'esistenza del file e carica il modello\n",
        "if not os.path.exists(PERCORSO_MODELLO_COMPLETO):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"‚ùå ERRORE: Il file GGUF NON √® stato trovato al percorso:\")\n",
        "    print(f\"Percorso cercato: {PERCORSO_MODELLO_COMPLETO}\")\n",
        "    print(\"Controlla che il file GGUF e il nome siano corretti.\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(f\"‚úÖ File del modello trovato: {PERCORSO_MODELLO_COMPLETO}\")\n",
        "    try:\n",
        "        print(\"\\nCaricamento del modello in corso... (Questo √® il passo che richiede pi√π tempo: circa 2 minuti)\")\n",
        "        llm = Llama(\n",
        "            model_path=PERCORSO_MODELLO_COMPLETO,\n",
        "            n_gpu_layers=-1, # Offload completo sulla GPU\n",
        "            n_ctx=4096,\n",
        "            verbose=False\n",
        "        )\n",
        "        print(\"üéâ Modello Gemma caricato e pronto per l'inferenza!\")\n",
        "    except Exception as e:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"‚ùå ERRORE GRAVE durante il caricamento del modello. Dettagli: {e}\")\n",
        "        print(\"Controlla la configurazione della GPU e la validit√† del file GGUF.\")\n",
        "        print(\"=\"*50)"
      ],
      "metadata": {
        "id": "5hE4egyXYU5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d5d1ca-246d-4b15-c48c-daea6b5d252d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Caricamento Modello ---\n",
            "‚úÖ File del modello trovato: /content/drive/MyDrive/LLM Models/gemma-2-2b-it-Q8_0.gguf\n",
            "\n",
            "Caricamento del modello in corso... (Questo √® il passo che richiede pi√π tempo: circa 2 minuti)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (4096) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Modello Gemma caricato e pronto per l'inferenza!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 5"
      ],
      "metadata": {
        "id": "RQ4cRcLdjBdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2838f98e-39b0-4e7d-eecb-b55c99c72f87",
        "id": "aRFYKxRqWIrX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Definizione Funzione ---\n",
            "‚úÖ Funzione 'generate_response' definita. Pronto per la Cella 6.\n"
          ]
        }
      ],
      "source": [
        "# Cella 5: Definizione della funzione di Inferenza\n",
        "print(\"--- 3. Definizione Funzione ---\")\n",
        "\n",
        "def generate_response(llm_model, user_prompt, max_tokens=2024, temperature=0.7, stop_sequence=[\"<end_of_turn>\"]):\n",
        "    \"\"\"\n",
        "    Funzione riutilizzabile per generare risposte da un modello Gemma Instruct.\n",
        "    \"\"\"\n",
        "    if llm_model is None:\n",
        "        return \"Errore: Il modello LLM non √® stato caricato correttamente nella Cella 2.\"\n",
        "\n",
        "    # Formattazione specifica per Gemma Instruct\n",
        "    prompt_formattato = f\"<start_of_turn>user\\n{user_prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "    output = llm_model(\n",
        "        prompt_formattato,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stop=stop_sequence,\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    # Estrai il testo e rimuovi spazi extra\n",
        "    return output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "print(\"‚úÖ Funzione 'generate_response' definita. Pronto per la Cella 6.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 6"
      ],
      "metadata": {
        "id": "MuDjNn9VjExP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42df2576-13e0-4875-9046-4d418b56954b",
        "id": "fm1k46WyWFov"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4. Esecuzione Test ---\n",
            "Domanda inviata a Gemma: Scrivimi un bigliettino di auguri per il compleanno\n",
            "\n",
            "==================================================\n",
            "--- RISPOSTA GENERATA ---\n",
            "Ecco alcuni biglietti di auguri per il compleanno, che puoi personalizzare:\n",
            "\n",
            "**Opzione 1: Classica e semplice**\n",
            "\n",
            "> Buon compleanno! üéÇ Ti auguro una giornata piena di gioia, risate e momenti indimenticabili. üéà\n",
            "\n",
            "**Opzione 2: Pi√π informale**\n",
            "\n",
            ">  üéâ  Congratulazioni per il tuo compleanno!  ü•≥  Che tu possa festeggiare in grande stile! ü•Ç\n",
            "\n",
            "**Opzione 3:  Con un tocco di humor**\n",
            "\n",
            ">  Happy Birthday!  üéâ  Spero che questa giornata sia piena di regali, dolci e anche un po' di pazzia! üòâ\n",
            "\n",
            "**Opzione 4:  Personalizzata**\n",
            "\n",
            ">  Buon compleanno, [nome]!  üéÇ Ti auguro una giornata speciale, piena di sorrisi, amore e tutto quello che ti rende felice!  ‚ù§Ô∏è\n",
            "\n",
            "\n",
            "**Consigli extra:**\n",
            "\n",
            "* Aggiungi una foto di voi insieme, se possibile.\n",
            "* Scrivi un breve messaggio personalizzato, che ricordi un ricordo speciale.\n",
            "* Includere un pensiero o una battuta che si adatti al tuo rapporto con la persona.\n",
            "\n",
            "\n",
            "\n",
            "Buon divertimento!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Cella 6: fai la domanda e ottieni la risposta\n",
        "print(\"--- 4. Esecuzione Test ---\")\n",
        "\n",
        "# Definisci la tua domanda qui\n",
        "PROMPT_UTENTE = \"Scrivimi un bigliettino di auguri per il compleanno\"\n",
        "\n",
        "print(f\"Domanda inviata a Gemma: {PROMPT_UTENTE}\")\n",
        "\n",
        "# Chiama la funzione\n",
        "risposta = generate_response(llm, PROMPT_UTENTE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA ---\")\n",
        "print(risposta)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13fed9ca"
      },
      "source": [
        "### 7. Creazione di un file di istruzioni (esempio)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c2029e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a54b333-e078-4295-cec6-abaa004e0d23"
      },
      "source": [
        "# Cella 7\n",
        "# Definisci il percorso e il nome del file di istruzioni\n",
        "FILE_ISTRUZIONI = \"istruzioni_personalizzate.txt\"\n",
        "\n",
        "# Contenuto delle istruzioni\n",
        "# Questo √® ci√≤ che il tuo modello \"legger√†\" prima del tuo prompt principale\n",
        "contenuto_istruzioni = (\n",
        "    \"Sei un assistente AI amichevole e collaborativo. \"\n",
        "    \"Rispondi sempre in italiano. \\n\"\n",
        "    \"Fornisci risposte dettagliate e utili, ma sii conciso quando possibile.\"\n",
        "    \"Presenta sempre il codice formattato correttamente con i blocchi di codice. \\n\"\n",
        "    \"Evita di aggiungere saluti o ringraziamenti.\"\n",
        "    \"Rispondi direttamente alla domanda dell'utente.\"\n",
        ")\n",
        "\n",
        "# Scrivi le istruzioni nel file\n",
        "with open(FILE_ISTRUZIONI, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(contenuto_istruzioni)\n",
        "\n",
        "print(f\"File '{FILE_ISTRUZIONI}' creato con successo.\\nContenuto:\\n{contenuto_istruzioni}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'istruzioni_personalizzate.txt' creato con successo.\n",
            "Contenuto:\n",
            "Sei un assistente AI amichevole e collaborativo. Rispondi sempre in italiano. \n",
            "Fornisci risposte dettagliate e utili, ma sii conciso quando possibile.Presenta sempre il codice formattato correttamente con i blocchi di codice. \n",
            "Evita di aggiungere saluti o ringraziamenti.Rispondi direttamente alla domanda dell'utente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67240068-7019-42ca-db99-565f654c19e8",
        "id": "hlTQ9aX6IU62"
      },
      "source": [
        "# cella 8:\n",
        "# Leggi le istruzioni dal file\n",
        "try:\n",
        "    with open(FILE_ISTRUZIONI, \"r\", encoding=\"utf-8\") as f:\n",
        "        istruzioni_da_file = f.read()\n",
        "    print(f\"Istruzioni lette dal file '{FILE_ISTRUZIONI}'.\")\n",
        "except FileNotFoundError:\n",
        "    istruzioni_da_file = \"\"\n",
        "    print(f\"‚ùå ERRORE: File di istruzioni '{FILE_ISTRUZIONI}' non trovato.\")\n",
        "\n",
        "# Prompt principale dell'utente\n",
        "PROMPT_UTENTE_AGGIUNTIVO = \"crea un programma in python per montare google drive\"\n",
        "\n",
        "# Combina le istruzioni con il prompt dell'utente\n",
        "# Puoi decidere come strutturare il prompt combinato.\n",
        "# Ad esempio, prima le istruzioni, poi la domanda specifica.\n",
        "PROMPT_FINALE = f\"{istruzioni_da_file.strip()}\\n\\nUtente: {PROMPT_UTENTE_AGGIUNTIVO}\"\n",
        "\n",
        "print(f\"\\nPrompt finale inviato a Gemma:\\n---\\n{PROMPT_FINALE}\\n---\")\n",
        "\n",
        "# Chiama la funzione con il nuovo prompt combinato\n",
        "risposta_con_istruzioni = generate_response(llm, PROMPT_FINALE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA CON ISTRUZIONI --- \")\n",
        "print(risposta_con_istruzioni)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# IMPORTANTE: Metti la chiusura della connessione alla fine del notebook\n",
        "# o quando sai che non dovrai pi√π accedere al DB in questa sessione,\n",
        "# altrimenti potresti avere errori se provi ad accedervi di nuovo.\n",
        "# conn.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Istruzioni lette dal file 'istruzioni_personalizzate.txt'.\n",
            "\n",
            "Prompt finale inviato a Gemma:\n",
            "---\n",
            "Sei un assistente AI amichevole e collaborativo. Rispondi sempre in italiano. \n",
            "Fornisci risposte dettagliate e utili, ma sii conciso quando possibile.Presenta sempre il codice formattato correttamente con i blocchi di codice. \n",
            "Evita di aggiungere saluti o ringraziamenti.Rispondi direttamente alla domanda dell'utente.\n",
            "\n",
            "Utente: grea un programma in python per montare google drive\n",
            "---\n",
            "\n",
            "==================================================\n",
            "--- RISPOSTA GENERATA CON ISTRUZIONI --- \n",
            "```python\n",
            "import os\n",
            "from google.auth import default\n",
            "from googleapiclient.discovery import build\n",
            "\n",
            "# Ottieni le credenziali di accesso dal file di configurazione\n",
            "creds = default()\n",
            "service = build('drive', 'v3', credentials=creds)\n",
            "\n",
            "# Definisci il percorso del file da montare\n",
            "file_path = 'path/to/file.txt'\n",
            "\n",
            "# Carica il file\n",
            "file_content = open(file_path, 'r').read()\n",
            "\n",
            "# Crea un oggetto di file di Google Drive\n",
            "file = service.files().create(\n",
            "    body={'name': 'montado_file.txt', 'mimeType': 'text/plain', 'body': file_content}\n",
            ").execute()\n",
            "\n",
            "# Stampa l'ID del file\n",
            "print(f'ID del file: {file[\"id\"]}')\n",
            "```\n",
            "\n",
            "**Spiegazione:**\n",
            "\n",
            "1. **Import delle librerie:** \n",
            "    * `os`: Per interagire con il sistema operativo.\n",
            "    * `google.auth.default`: Per ottenere le credenziali di accesso dal file di configurazione.\n",
            "    * `googleapiclient.discovery`: Per interagire con i servizi di Google Drive.\n",
            "\n",
            "2. **Ottieni le credenziali di accesso:** \n",
            "    * `default()`: Ritorna le credenziali di accesso preconfigurate.\n",
            "\n",
            "3. **Crea un oggetto di file di Google Drive:** \n",
            "    * `service = build('drive', 'v3', credentials=creds)`: Crea un oggetto di servizio per interagire con il servizio Drive.\n",
            "    * `service.files().create()`: Crea un nuovo file.\n",
            "    * `body={'name': 'montado_file.txt', 'mimeType': 'text/plain', 'body': file_content}`: Imposta il nome del file, il tipo di MIME e il contenuto del file.\n",
            "\n",
            "4. **Stampa l'ID del file:** \n",
            "    * `print(f'ID del file: {file[\"id\"]}')`: Stampa l'ID del file.\n",
            "\n",
            "**Note:** \n",
            "\n",
            "* Sostituisci `'path/to/file.txt'` con il percorso del file che vuoi montare.\n",
            "* Assicurati di avere le credenziali di accesso Google Drive configurate correttamente.\n",
            "* Questo codice crea un file di testo chiamato `montado_file.txt` nel tuo account Google Drive.\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dd157b-561d-41ee-b858-8198a0075b93",
        "id": "ewngbSspIRH3"
      },
      "source": [
        "# cella 8:\n",
        "# Leggi le istruzioni dal file\n",
        "try:\n",
        "    with open(FILE_ISTRUZIONI, \"r\", encoding=\"utf-8\") as f:\n",
        "        istruzioni_da_file = f.read()\n",
        "    print(f\"Istruzioni lette dal file '{FILE_ISTRUZIONI}'.\")\n",
        "except FileNotFoundError:\n",
        "    istruzioni_da_file = \"\"\n",
        "    print(f\"‚ùå ERRORE: File di istruzioni '{FILE_ISTRUZIONI}' non trovato.\")\n",
        "\n",
        "# Prompt principale dell'utente\n",
        "PROMPT_UTENTE_AGGIUNTIVO = \"spiegami che tool posso inserire con facilit√† in un Agent AI.\"\n",
        "\n",
        "# Combina le istruzioni con il prompt dell'utente\n",
        "# Puoi decidere come strutturare il prompt combinato.\n",
        "# Ad esempio, prima le istruzioni, poi la domanda specifica.\n",
        "PROMPT_FINALE = f\"{istruzioni_da_file.strip()}\\n\\nUtente: {PROMPT_UTENTE_AGGIUNTIVO}\"\n",
        "\n",
        "print(f\"\\nPrompt finale inviato a Gemma:\\n---\\n{PROMPT_FINALE}\\n---\")\n",
        "\n",
        "# Chiama la funzione con il nuovo prompt combinato\n",
        "risposta_con_istruzioni = generate_response(llm, PROMPT_FINALE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA CON ISTRUZIONI --- \")\n",
        "print(risposta_con_istruzioni)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# IMPORTANTE: Metti la chiusura della connessione alla fine del notebook\n",
        "# o quando sai che non dovrai pi√π accedere al DB in questa sessione,\n",
        "# altrimenti potresti avere errori se provi ad accedervi di nuovo.\n",
        "# conn.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Istruzioni lette dal file 'istruzioni_personalizzate.txt'.\n",
            "\n",
            "Prompt finale inviato a Gemma:\n",
            "---\n",
            "Sei un assistente AI amichevole e collaborativo. Rispondi sempre in italiano. Fornisci risposte dettagliate e utili, ma sii conciso quando possibile.Presenta sempre il codice formattato correttamente con i blocchi di codice.Evita di aggiungere saluti o ringraziamenti.Rispondi direttamente alla domanda dell'utente.\n",
            "\n",
            "Utente: spiegami che tool posso inserire con facilit√† in un Agent AI.\n",
            "---\n",
            "\n",
            "==================================================\n",
            "--- RISPOSTA GENERATA CON ISTRUZIONI --- \n",
            "Ecco alcuni tool che puoi inserire con facilit√† in un Agent AI, con un focus su funzionalit√† e vantaggi:\n",
            "\n",
            "**Per l'interazione con i dati:**\n",
            "\n",
            "* **OpenAI API:**  Per l'accesso a modelli linguistici come ChatGPT. Puoi utilizzare l'API per generare testo, tradurre, riassumere, e molto altro.\n",
            "  ```python\n",
            "  import openai\n",
            "\n",
            "  openai.api_key = \"YOUR_API_KEY\"\n",
            "\n",
            "  response = openai.Completion.create(\n",
            "    engine=\"text-davinci-003\", # Puoi scegliere un modello specifico\n",
            "    prompt=\"Scrivi una poesia sul mare\", \n",
            "    max_tokens=100\n",
            "  )\n",
            "  print(response.choices[0].text)\n",
            "  ```\n",
            "\n",
            "* **Google Cloud Natural Language API:**  Per analisi sentimentale, topic extraction e riconoscimento di entit√†.\n",
            "  ```python\n",
            "  # Sostituisci con i tuoi credenziali Google Cloud\n",
            "  from google.cloud import language_v1\n",
            "\n",
            "  client = language_v1.LanguageServiceClient()\n",
            "\n",
            "  document = b\"Il sole √® splendente oggi.\" \n",
            "  # Analisi sentimentale\n",
            "  response = client.analyze_sentiment(document=document)\n",
            "  print(f\"Sentiment: {response.document_sentiment.label}\")\n",
            "  ```\n",
            "\n",
            "* **Elasticsearch:**  Per la gestione e l'analisi di grandi quantit√† di dati. Puoi usarlo per migliorare l'interazione con i dati e fornire risposte pi√π precise.\n",
            "\n",
            "**Per l'elaborazione del linguaggio naturale:**\n",
            "\n",
            "* **Hugging Face Transformers:**  Un framework open source per l'apprendimento automatico del linguaggio. Puoi utilizzare modelli pre-addestrati per compiti come la generazione di testo, la traduzione e la risposta alle domande. \n",
            "  ```python\n",
            "  from transformers import pipeline\n",
            "\n",
            "  generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
            "  result = generator(\"Ciao, come stai?\", max_length=50)\n",
            "  print(result)\n",
            "  ```\n",
            "\n",
            "* **SpaCy:**  Un pacchetto Python per l'analisi del linguaggio naturale. Puoi usarlo per la tokenizzazione, la part-of-speech tagging e il riconoscimento di entit√†.\n",
            "\n",
            "**Per l'integrazione con altri servizi:**\n",
            "\n",
            "* **Zapier:**  Per automatizzare la comunicazione tra diversi servizi. Puoi usare Zapier per integrare l'Agent AI con servizi come email, calendari, piattaforme di CRM e altri.\n",
            "\n",
            "\n",
            "**Ricorda di:**\n",
            "\n",
            "* Scegliere il tool che meglio si adatta alle tue esigenze specifiche.\n",
            "* Leggere la documentazione del tool prima di utilizzarlo.\n",
            "* Potrebbe essere necessario configurare un account e ottenere una chiave API per alcuni tool.\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077935ad"
      },
      "source": [
        "### 8. Lettura del file e integrazione nel prompt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fc547fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dd157b-561d-41ee-b858-8198a0075b93"
      },
      "source": [
        "# cella 8:\n",
        "# Leggi le istruzioni dal file\n",
        "try:\n",
        "    with open(FILE_ISTRUZIONI, \"r\", encoding=\"utf-8\") as f:\n",
        "        istruzioni_da_file = f.read()\n",
        "    print(f\"Istruzioni lette dal file '{FILE_ISTRUZIONI}'.\")\n",
        "except FileNotFoundError:\n",
        "    istruzioni_da_file = \"\"\n",
        "    print(f\"‚ùå ERRORE: File di istruzioni '{FILE_ISTRUZIONI}' non trovato.\")\n",
        "\n",
        "# Prompt principale dell'utente\n",
        "PROMPT_UTENTE_AGGIUNTIVO = \"spiegami che tool posso inserire con facilit√† in un Agent AI.\"\n",
        "\n",
        "# Combina le istruzioni con il prompt dell'utente\n",
        "# Puoi decidere come strutturare il prompt combinato.\n",
        "# Ad esempio, prima le istruzioni, poi la domanda specifica.\n",
        "PROMPT_FINALE = f\"{istruzioni_da_file.strip()}\\n\\nUtente: {PROMPT_UTENTE_AGGIUNTIVO}\"\n",
        "\n",
        "print(f\"\\nPrompt finale inviato a Gemma:\\n---\\n{PROMPT_FINALE}\\n---\")\n",
        "\n",
        "# Chiama la funzione con il nuovo prompt combinato\n",
        "risposta_con_istruzioni = generate_response(llm, PROMPT_FINALE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA CON ISTRUZIONI --- \")\n",
        "print(risposta_con_istruzioni)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# IMPORTANTE: Metti la chiusura della connessione alla fine del notebook\n",
        "# o quando sai che non dovrai pi√π accedere al DB in questa sessione,\n",
        "# altrimenti potresti avere errori se provi ad accedervi di nuovo.\n",
        "# conn.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Istruzioni lette dal file 'istruzioni_personalizzate.txt'.\n",
            "\n",
            "Prompt finale inviato a Gemma:\n",
            "---\n",
            "Sei un assistente AI amichevole e collaborativo. Rispondi sempre in italiano. Fornisci risposte dettagliate e utili, ma sii conciso quando possibile.Presenta sempre il codice formattato correttamente con i blocchi di codice.Evita di aggiungere saluti o ringraziamenti.Rispondi direttamente alla domanda dell'utente.\n",
            "\n",
            "Utente: spiegami che tool posso inserire con facilit√† in un Agent AI.\n",
            "---\n",
            "\n",
            "==================================================\n",
            "--- RISPOSTA GENERATA CON ISTRUZIONI --- \n",
            "Ecco alcuni tool che puoi inserire con facilit√† in un Agent AI, con un focus su funzionalit√† e vantaggi:\n",
            "\n",
            "**Per l'interazione con i dati:**\n",
            "\n",
            "* **OpenAI API:**  Per l'accesso a modelli linguistici come ChatGPT. Puoi utilizzare l'API per generare testo, tradurre, riassumere, e molto altro.\n",
            "  ```python\n",
            "  import openai\n",
            "\n",
            "  openai.api_key = \"YOUR_API_KEY\"\n",
            "\n",
            "  response = openai.Completion.create(\n",
            "    engine=\"text-davinci-003\", # Puoi scegliere un modello specifico\n",
            "    prompt=\"Scrivi una poesia sul mare\", \n",
            "    max_tokens=100\n",
            "  )\n",
            "  print(response.choices[0].text)\n",
            "  ```\n",
            "\n",
            "* **Google Cloud Natural Language API:**  Per analisi sentimentale, topic extraction e riconoscimento di entit√†.\n",
            "  ```python\n",
            "  # Sostituisci con i tuoi credenziali Google Cloud\n",
            "  from google.cloud import language_v1\n",
            "\n",
            "  client = language_v1.LanguageServiceClient()\n",
            "\n",
            "  document = b\"Il sole √® splendente oggi.\" \n",
            "  # Analisi sentimentale\n",
            "  response = client.analyze_sentiment(document=document)\n",
            "  print(f\"Sentiment: {response.document_sentiment.label}\")\n",
            "  ```\n",
            "\n",
            "* **Elasticsearch:**  Per la gestione e l'analisi di grandi quantit√† di dati. Puoi usarlo per migliorare l'interazione con i dati e fornire risposte pi√π precise.\n",
            "\n",
            "**Per l'elaborazione del linguaggio naturale:**\n",
            "\n",
            "* **Hugging Face Transformers:**  Un framework open source per l'apprendimento automatico del linguaggio. Puoi utilizzare modelli pre-addestrati per compiti come la generazione di testo, la traduzione e la risposta alle domande. \n",
            "  ```python\n",
            "  from transformers import pipeline\n",
            "\n",
            "  generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
            "  result = generator(\"Ciao, come stai?\", max_length=50)\n",
            "  print(result)\n",
            "  ```\n",
            "\n",
            "* **SpaCy:**  Un pacchetto Python per l'analisi del linguaggio naturale. Puoi usarlo per la tokenizzazione, la part-of-speech tagging e il riconoscimento di entit√†.\n",
            "\n",
            "**Per l'integrazione con altri servizi:**\n",
            "\n",
            "* **Zapier:**  Per automatizzare la comunicazione tra diversi servizi. Puoi usare Zapier per integrare l'Agent AI con servizi come email, calendari, piattaforme di CRM e altri.\n",
            "\n",
            "\n",
            "**Ricorda di:**\n",
            "\n",
            "* Scegliere il tool che meglio si adatta alle tue esigenze specifiche.\n",
            "* Leggere la documentazione del tool prima di utilizzarlo.\n",
            "* Potrebbe essere necessario configurare un account e ottenere una chiave API per alcuni tool.\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a5f911b"
      },
      "source": [
        "### 9. Integrazione delle Istruzioni dal Database e Nuovo Ciclo di Chat\n",
        "Questa sezione mostra come recuperare le istruzioni dal database SQLite e integrarle in un prompt per una conversazione interattiva con l'agente AI. Questo √® un passo avanti rispetto alla gestione statica delle istruzioni da file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90c950a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "e4c9a5a3-953e-4892-ea7b-210977d5ad23"
      },
      "source": [
        "# Cella 9: Integrazione Istruzioni dal DB in un loop di chat\n",
        "\n",
        "# Riutilizziamo la funzione definita in Cella 6 per recuperare tutte le istruzioni\n",
        "# Assicurati che 'conn' e 'cursor' siano ancora aperti dalla Cella 6. Se hai chiuso la connessione, riaprila qui.\n",
        "\n",
        "import sqlite3 # Ensure sqlite3 is imported in this cell for robustness\n",
        "\n",
        "# Fix: sqlite3.Connection objects do not have a 'closed' attribute.\n",
        "# To handle the case where 'conn' might be closed from a previous cell\n",
        "# (as `conn.close()` was called in cell 1fc547fa), we should always re-establish the connection.\n",
        "# We'll explicitly close any existing connection before opening a new one,\n",
        "# which is good practice to ensure a clean state, even if already closed or unusable.\n",
        "if 'conn' in globals() and isinstance(globals().get('conn'), sqlite3.Connection):\n",
        "    try:\n",
        "        globals()['conn'].close()\n",
        "        print(\"Existing database connection explicitly closed before re-opening.\")\n",
        "    except Exception as e:\n",
        "        # This catch is mostly for cases where 'conn' exists but is somehow corrupted\n",
        "        print(f\"Warning: Could not close existing connection cleanly: {e}\")\n",
        "    conn = None # Reset conn to ensure a new connection is made\n",
        "\n",
        "print(\"Riapro la connessione al database...\")\n",
        "try:\n",
        "    conn = sqlite3.connect(PERCORSO_DB_COMPLETO)\n",
        "    cursor = conn.cursor()\n",
        "    print(\"‚úÖ Connessione al database SQLite riaperta.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERRORE: Impossibile riaprire la connessione al database. {e}\")\n",
        "\n",
        "def get_all_instructions_content(cursor_obj):\n",
        "    cursor_obj.execute(\"SELECT content FROM instructions ORDER BY id\")\n",
        "    return \"\\n\".join([row[0] for row in cursor_obj.fetchall()])\n",
        "\n",
        "# Recupera tutte le istruzioni dal database\n",
        "db_instructions = get_all_instructions_content(cursor)\n",
        "\n",
        "print(\"--- Istruzioni dal Database ---\")\n",
        "print(db_instructions)\n",
        "print(\"-------------------------------\")\n",
        "\n",
        "# Iniziamo una storia di conversazione\n",
        "conversation_history = []\n",
        "\n",
        "# Funzione per generare una risposta combinando istruzioni e storia\n",
        "def generate_chat_response(llm_model, user_input, history, system_instructions, max_tokens=2024, temperature=0.7, stop_sequence=[\"<end_of_turn>\"]):\n",
        "    # Costruisci il prompt combinando istruzioni, storia e input utente\n",
        "    full_prompt = f\"{system_instructions.strip()}\\n\\n\"\n",
        "\n",
        "    for role, message in history:\n",
        "        if role == \"user\":\n",
        "            full_prompt += f\"<start_of_turn>user\\n{message}<end_of_turn>\\n\"\n",
        "        elif role == \"model\":\n",
        "            full_prompt += f\"<start_of_turn>model\\n{message}<end_of_turn>\\n\"\n",
        "\n",
        "    full_prompt += f\"<start_of_turn>user\\n{user_input}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "    print(f\"\\nDEBUG: Prompt completo inviato al modello:\\n---\\n{full_prompt}\\n---\\n\")\n",
        "\n",
        "    output = llm_model(\n",
        "        full_prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stop=stop_sequence,\n",
        "        echo=False\n",
        "    )\n",
        "    return output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "\n",
        "print(\"\\n--- Inizia la conversazione (digita 'esci' per terminare) ---\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Utente: \")\n",
        "    if user_input.lower() == 'esci':\n",
        "        break\n",
        "\n",
        "    response = generate_chat_response(llm, user_input, conversation_history, db_instructions)\n",
        "\n",
        "    print(f\"Agente: {response}\")\n",
        "\n",
        "    # Aggiungi la conversazione alla storia\n",
        "    conversation_history.append((\"user\", user_input))\n",
        "    conversation_history.append((\"model\", response))\n",
        "\n",
        "print(\"\\n--- Conversazione terminata ---\")\n",
        "\n",
        "# √à buona pratica chiudere la connessione al DB quando non serve pi√π\n",
        "# Fix: sqlite3.Connection objects do not have a 'closed' attribute.\n",
        "# A simpler check for sqlite3 is to see if 'conn' exists and is a connection object.\n",
        "if 'conn' in globals() and isinstance(globals().get('conn'), sqlite3.Connection):\n",
        "    try:\n",
        "        globals()['conn'].close()\n",
        "        print(\"Connessione al database chiusa.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not close connection during final cleanup: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Riapro la connessione al database...\n",
            "‚ùå ERRORE: Impossibile riaprire la connessione al database. name 'PERCORSO_DB_COMPLETO' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cursor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2382742065.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Recupera tutte le istruzioni dal database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mdb_instructions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_instructions_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Istruzioni dal Database ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cursor' is not defined"
          ]
        }
      ]
    }
  ]
}