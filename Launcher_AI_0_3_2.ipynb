{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZDAm4/8ud23LGgLLGbbkG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdce252e"
      },
      "source": [
        "### Cella 0: stato iniziale\n",
        "\n",
        "Questa cella stampa la versione di Python e di tutte le librerie in uso nell'ambiente Colab, quindi effettua un chek di compatibilit√† librerie. Questo √® utile per la risoluzione dei problemi di dipendenza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab99f58f",
        "collapsed": true
      },
      "source": [
        "# Cella 0\n",
        "\n",
        "from pathlib import Path\n",
        "import os, sys\n",
        "import shutil\n",
        "print(\"Versione del file 0.3.1, pushata in github\\n Versione Python:\")\n",
        "print(sys.version)\n",
        "print(f\"PATH (Eseguibili):\\n {os.environ['PATH']}\")\n",
        "print(f\"sys.path (Librerie Python):\\n {sys.path}\")\n",
        "print(Path.cwd())\n",
        "# !pip list # decommentare per leggere l'elenco di librerie preinstallate\n",
        "# in caso di anomalia del seguente check\n",
        "!pip check\n",
        "\n",
        "# ==============================================================================\n",
        "# Fase 1: RILEVAZIONE AMBIENTE E SETTAGGIO BRANCH\n",
        "# ==============================================================================\n",
        "# 1.1 Logica di rilevazione\n",
        "if Path(\"/content\").exists():\n",
        "    ENV = \"COLAB\"\n",
        "    ROOT = Path(\"/content\")\n",
        "    BRANCH = \"sviluppo\"\n",
        "elif Path(\"/home/studio-lab-user\").exists():\n",
        "    ENV = \"SAGEMAKER\"\n",
        "    ROOT = Path(\"/home/studio-lab-user\")\n",
        "#   BRANCH = \"main\" da ripristinare quando collaudato\n",
        "    BRANCH = \"sviluppo\"\n",
        "else:\n",
        "    ENV = \"UNKNOWN\"\n",
        "    ROOT = Path(os.getcwd())\n",
        "    BRANCH = \"main\"\n",
        "    print(\"‚ö†Ô∏è Non sei nella Root di un ambiente conosciuto.\")\n",
        "\n",
        "# 1.2 Variabili derivate\n",
        "# Usiamo 'repo' e 'modules' come nomi standard per facilitare la gestione delle celle future.\n",
        "REPO_LOCAL = ROOT / \"repo\"        # Dove scaricheremo tutto il repository\n",
        "TARGET_MODULES = ROOT / \"modules\"    # Dove copieremo i moduli per Python\n",
        "REPO_URL   = \"https://github.com/Theridel/Coach_2.0.git\"\n",
        "\n",
        "# 1.4 Output unico di riepilogo\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"üåç AMBIENTE : {ENV}\")\n",
        "print(f\"üåø BRANCH   : {BRANCH}\")\n",
        "print(f\"üìÅ ROOT     : {ROOT}\")\n",
        "print(f\"üìÇ REPO     : {REPO_LOCAL}\")\n",
        "print(f\"üìÇ MODULES  : {TARGET_MODULES}\")\n",
        "print(f\"{'='*40}\")\n",
        "print(\"puoi scaricare il repository\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 1: Scarica il repository da github e Installazione delle dipendenze\n",
        "\n",
        "1. **Scaricamento del repository**: tutto il repository viene copiato nella directory /content/repo. Da questo, copiamo il contenuto di /runtime su /content\n",
        "2. **Installazione di varie librerie da requirements.txt**: Vengono installate librerie essenziali come `llama-cpp-python`, per l'interazione con i modelli GGUF (come Gemma). L'opzione `--upgrade` assicura di avere l'ultima versione e `-q` la rende silenziosa."
      ],
      "metadata": {
        "id": "dcuU0t1CqnAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 1\n",
        "\n",
        "# ==============================================================================\n",
        "# Fase 2: Scarica il repository da github\n",
        "# ==============================================================================\n",
        "\n",
        "# 2.1 Pulizia della directory (Strategica per Colab e SageMaker)\n",
        "if ENV == \"COLAB\":\n",
        "    print(f\"[CLEAN] Pulizia totale Colab (eccetto Drive)...\")\n",
        "    for item in ROOT.iterdir():\n",
        "        if item.name == \"drive\":\n",
        "            continue\n",
        "        try:\n",
        "            if item.is_dir():\n",
        "                shutil.rmtree(item)\n",
        "            else:\n",
        "                item.unlink()\n",
        "        except Exception as e:\n",
        "            print(f\"Errore: {e}\")\n",
        "\n",
        "elif ENV == \"SAGEMAKER\":\n",
        "    print(f\"[CLEAN] SageMaker: Pulizia selettiva per evitare accumulo residui...\")\n",
        "    # Definiamo cosa vogliamo che sia SEMPRE pulito prima di un nuovo \"travaso\"\n",
        "    pulizia_target = [REPO_LOCAL, TARGET_MODULES]\n",
        "\n",
        "    for cartella in pulizia_target:\n",
        "        if cartella.exists():\n",
        "            print(f\"   - Rimozione residui: {cartella.name}\")\n",
        "            shutil.rmtree(cartella)\n",
        "\n",
        "print(f\"[INFO] Pronto per Fase 2 (Clone) su {REPO_LOCAL}\")\n",
        "\n",
        "# 2.2: Clone del repository Git.\n",
        "# Esegue un 'git clone' per scaricare il repository per la prima volta.\n",
        "print(\"[PACK] Clono il repo...\")\n",
        "os.system(f\"git clone -b {BRANCH} {REPO_URL} {REPO_LOCAL}\") # Clona il repo usando os.system\n",
        "\n",
        "# ==============================================================================\n",
        "# Fase 3: Installa le dipendenze, copia del contenuto del repository\n",
        "# a ROOT, /content/ per COLAB e /studio-lab-user per Sagemaker.\n",
        "# ==============================================================================\n",
        "\n",
        "# 3.1 copia da /repo\n",
        "# La variabile 'src' punta alla directory 'runtime' all'interno del repository clonato.\n",
        "src = REPO_LOCAL  # Puntiamo direttamente alla cartella principale del repo\n",
        "\n",
        "# Viene eseguito un controllo per assicurarsi che la cartella 'runtime' esista.\n",
        "# Ogni elemento (file o directory) all'interno di 'runtime' viene copiato direttamente in /content/.\n",
        "# Se √® una directory, usa shutil.copytree; altrimenti, usa shutil.copy2 per i file.\n",
        "\n",
        "for item in src.iterdir():\n",
        "    if item.name == \".git\": continue # <--- Aggiungi questa riga\n",
        "    target = ROOT / item.name\n",
        "    if item.is_dir(): # <--- Deve essere allineato sotto 'target'\n",
        "        if target.exists():\n",
        "            shutil.rmtree(target)\n",
        "        shutil.copytree(item, target)\n",
        "    else:\n",
        "        shutil.copy2(item, target) # <--- Ricordati di aggiungere questo per i file singoli!\n",
        "\n",
        "print(\"[PACK] Copia completata: runtime/* ‚Üí /content/\")\n",
        "\n",
        "# 3.2 Installa le librerie necessarie\n",
        "%pip install -r {REPO_LOCAL}/requirements.txt --upgrade\n",
        "print(\"Dipendenze installate da requirements.txt.\")\n",
        "\n",
        "%pip install -r {REPO_LOCAL}/requirements_AI.txt --upgrade\n",
        "print(\"Dipendenze installate da requirements_AI.txt.\")\n",
        "\n",
        "\n",
        "# 3.3: Copia selettivadella directory /modules\n",
        "\n",
        "# Definiamo sorgente e destinazione per i moduli\n",
        "SORGENTE_MODULES = REPO_LOCAL / \"modules\"\n",
        "# TARGET_MODULES √® gi√† definita come ROOT / \"modules\" nella tua Fase 1.2\n",
        "\n",
        "if SORGENTE_MODULES.exists() and SORGENTE_MODULES.is_dir():\n",
        "    print(f\"[PACK] Sincronizzazione moduli: {SORGENTE_MODULES} ‚Üí {TARGET_MODULES}\")\n",
        "\n",
        "    # Se la cartella di destinazione esiste gi√†, la rimuoviamo per garantire una copia pulita\n",
        "    if TARGET_MODULES.exists():\n",
        "        shutil.rmtree(TARGET_MODULES)\n",
        "\n",
        "    # Copia ricorsiva di tutta la struttura (file .py, __init__.py e sottocartelle)\n",
        "    shutil.copytree(SORGENTE_MODULES, TARGET_MODULES)\n",
        "\n",
        "    # Aggiunta al path di sistema per permettere l'import immediato\n",
        "    if str(TARGET_MODULES) not in sys.path:\n",
        "        sys.path.append(str(TARGET_MODULES))\n",
        "        print(f\"‚úÖ Moduli pronti per l'import e aggiunti al sys.path\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Attenzione: La directory /modules non √® stata trovata nel repository clonato.\")\n",
        "\n",
        "print(\"Pronto per SETUP (cella 2). Puoi controllare il download con la cella Test\")"
      ],
      "metadata": {
        "id": "UCxG1C7ot5aa",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cella 2  di comodo:\n",
        "Cella 2: Setup\n",
        "Questa cella si occupa della configurazione iniziale dell'ambiente.\n",
        "\n",
        "## crea variabile dizionario \"ambiente\"\n",
        "\n",
        "\n",
        "Da spostare\n",
        "\n",
        "Montaggio di Google Drive: Viene montato Google Drive nel file system di Colab. Questo √® fondamentale per poter accedere ai modelli GGUF salvati.\n",
        "Gestione errori: avvisa in caso di fallimento del montaggio.\n"
      ],
      "metadata": {
        "id": "3yruqe6BS_Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===============================================================================\n",
        "#   Fase 4. set up\n",
        "#===============================================================================\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# 4.1 definisco la funzione  get_env_context()\n",
        "# rileviamo percorsi e variabili utili e le inseriamo in un dizionario\n",
        "def get_env_context():\n",
        "    \"\"\"\n",
        "    Rileva l'infrastruttura e mappa i percorsi core.\n",
        "    Restituisce l'oggetto 'envir' (dizionario).\n",
        "    \"\"\"\n",
        "# Identificazione Ambiente\n",
        "    if Path(\"/content\").exists():\n",
        "        env_type = \"COLAB\"\n",
        "        root_path = Path(\"/content\")\n",
        "        git_branch = \"sviluppo\"\n",
        "    elif Path(\"/home/studio-lab-user\").exists():\n",
        "        env_type = \"SAGEMAKER\"\n",
        "        root_path = Path(\"/home/studio-lab-user\")\n",
        "        git_branch = \"sviluppo\"\n",
        "    else:\n",
        "        env_type = \"LOCAL\"\n",
        "        root_path = Path(os.getcwd())\n",
        "        git_branch = \"main\"\n",
        "\n",
        " # Costruzione dell'oggetto envir (La mappa delle risorse)\n",
        "    contesto = {\n",
        "        \"ENV\": env_type,\n",
        "        \"ROOT\": root_path,\n",
        "        \"BRANCH\": git_branch,\n",
        "        \"REPO_LOCAL\": root_path / \"repo\",\n",
        "        \"TARGET_MODULES\": root_path / \"modules\",\n",
        "\n",
        "        # DATABASE 1: SQLite (Locale)\n",
        "        \"PATH_DB_LOCAL\": root_path / \"agent_instructions.db\",\n",
        "\n",
        "        # DATABASE 2: Supabase (Remoto - Segnaposto per le chiavi)\n",
        "        \"SB_URL\": None,\n",
        "        \"SB_KEY\": None\n",
        "    }\n",
        "\n",
        "    return contesto\n",
        "\n",
        "# --- INIZIALIZZAZIONE GLOBALE ---\n",
        "# Queando questa riga viene eseguita, rende 'envir' disponibile in tutto il notebook\n",
        "envir = get_env_context()\n"
      ],
      "metadata": {
        "id": "fgwwKDw5TSes"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cella 3 di comodo\n",
        "## Uso le funzioni, nell'altro script importo i moduli"
      ],
      "metadata": {
        "id": "hXttFAIG5H8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from modules.envir_manager import get_env_context\n",
        "\n",
        "# 1. Recupero dei dati dal modulo\n",
        "# envir = get_env_context()\n",
        "\n",
        "# 2. Stampa di prova nel main per verifica visiva (come richiesto)\n",
        "print(f\"{'='*40}\")\n",
        "print(f\"VERIFICA AMBIENTE:\")\n",
        "for chiave, valore in envir.items():\n",
        "    print(f\"{chiave:15} : {valore}\")\n",
        "print(f\"{'='*40}\")\n",
        "\n",
        "# 3. Da qui in poi usi solo il dizionario ambiente\n",
        "# Esempio: os.chdir(ambiente['ROOT']"
      ],
      "metadata": {
        "id": "eQhCpwVt2Etf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1gw5f7Jlrha"
      },
      "source": [
        "### Cella 2: Setup\n",
        "Questa cella si occupa della configurazione iniziale dell'ambiente.\n",
        "\n",
        "1. **Montaggio di Google Drive**: Viene montato Google Drive nel file system di Colab. Questo √® fondamentale per poter accedere ai modelli GGUF salvati.\n",
        "2. **Gestione errori**: avvisa in caso di fallimento del montaggio."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 2: Setup (Versione con Secrets)\n",
        "\n",
        "# 1. Importa librerie e moduli\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from google.colab import userdata  # Necessario per i Secrets\n",
        "from datetime import datetime\n",
        "from supabase import create_client, Client\n",
        "\n",
        "# 2. Monta Google Drive\n",
        "print(\"--- 1. Monta Google Drive ---\")\n",
        "if not os.path.exists('/content/drive'):\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        print(\"‚úÖ Google Drive montato con successo.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRORE: Impossibile montare Google Drive. {e}\")\n",
        "\n",
        "# --- CONFIGURAZIONE SUPABASE (SICURA) ---\n",
        "# Recupero dai Secrets di Colab.\n",
        "# Nota: In un ambiente locale potresti usare un file .env per gestire queste variabili.\n",
        "try:\n",
        "    SUPABASE_URL = userdata.get('SUPABASE_URL')\n",
        "    SUPABASE_ANON_KEY = userdata.get('SUPABASE_ANON_KEY')\n",
        "    print(\"üîë Chiavi caricate dai Secrets di Colab.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Errore nel caricamento dei Secrets: {e}\")\n",
        "    print(\"Assicurati di aver aggiunto SUPABASE_URL e SUPABASE_ANON_KEY nel pannello Secrets.\")\n",
        "\n",
        "# --- CONFIGURAZIONE PERCORSI SQLITE ---\n",
        "NOME_DB = \"agent_instructions.db\"\n",
        "CARTELLA_DRIVE = \"/content/drive/MyDrive/LLM Database/\"\n",
        "PATH_REPO = f\"/content/repo/{NOME_DB}\"\n",
        "PATH_DRIVE = os.path.join(CARTELLA_DRIVE, NOME_DB)\n",
        "PATH_LAVORO = f\"/content/{NOME_DB}\"\n",
        "\n",
        "def setup_ambiente():\n",
        "    # --- Inizializzazione Supabase (Corretta) ---\n",
        "    global supabase\n",
        "    try:\n",
        "        supabase = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)\n",
        "        print(\"‚úÖ Connessione a Supabase stabilita.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Errore connessione Supabase: {e}\")\n",
        "\n",
        "    # --- Gestione SQLite (Tua logica originale) ---\n",
        "    os.makedirs(CARTELLA_DRIVE, exist_ok=True)\n",
        "    esiste_drive = os.path.exists(PATH_DRIVE)\n",
        "    esiste_repo = os.path.exists(PATH_REPO)\n",
        "\n",
        "    if esiste_drive:\n",
        "        print(f\"üì• Trovato database su Drive. Caricamento in corso...\")\n",
        "        shutil.copy2(PATH_DRIVE, PATH_LAVORO)\n",
        "    elif esiste_repo:\n",
        "        print(f\"üì¶ Drive vuoto. Caricamento dal Repo GitHub...\")\n",
        "        shutil.copy2(PATH_REPO, PATH_LAVORO)\n",
        "    else:\n",
        "        print(\"üÜï Nessun database SQLite trovato. Ne verr√† creato uno nuovo.\")\n",
        "\n",
        "    if esiste_drive and esiste_repo:\n",
        "        mtime_drive = os.path.getmtime(PATH_DRIVE)\n",
        "        mtime_repo = os.path.getmtime(PATH_REPO)\n",
        "        if abs(mtime_drive - mtime_repo) > 2:\n",
        "            print(f\"‚ö†Ô∏è AVVISO: Differenza tra Drive e Repo rilevata.\")\n",
        "\n",
        "    print(f\"‚úÖ Ambiente pronto. File di lavoro locale: {PATH_LAVORO}\")\n",
        "\n",
        "setup_ambiente()"
      ],
      "metadata": {
        "id": "92eJwyHz0sMM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cella test, verifichiamo:\n",
        "\n",
        "*   lo scaricamento del repository\n",
        "*   La variabile d'ambiente\n"
      ],
      "metadata": {
        "id": "XRVwyPUVy3Q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Recupero sicuro del path\n",
        "content_path = envir.get('ROOT')\n",
        "\n",
        "# Itera sugli elementi nella root\n",
        "for item in sorted(content_path.iterdir()):\n",
        "    # Esclusione specifica per il repo (troppo vasto da listare)\n",
        "    if item.is_dir() and item.name == \"repo\":\n",
        "        print(f\"üìÅ {item.name}/ [Directory Repo - Contenuto Nascosto]\")\n",
        "        continue\n",
        "\n",
        "    # Gestione Cartelle\n",
        "    if item.is_dir():\n",
        "        print(f\"üìÅ {item.name}/\")\n",
        "        sub_items = sorted(list(item.iterdir()))\n",
        "        if not sub_items:\n",
        "            print(\"    ‚îî‚îÄ‚îÄ (vuota)\")\n",
        "        else:\n",
        "            for sub_item in sub_items:\n",
        "                # Mostriamo solo i file o le sottocartelle immediate\n",
        "                prefisso = \"    ‚îú‚îÄ‚îÄ\" if sub_item != sub_items[-1] else \"    ‚îî‚îÄ‚îÄ\"\n",
        "                tipo = \"üìÅ \" if sub_item.is_dir() else \"üìÑ \"\n",
        "                print(f\"{prefisso} {tipo}{sub_item.name}\")\n",
        "\n",
        "    # Gestione File nella Root\n",
        "    elif item.is_file():\n",
        "        print(f\"üìÑ {item.name}\")\n",
        "\n",
        "print(f\"{'-'*45}\")\n",
        "\n",
        "# puliamo la chache delle librerie installate.\n",
        "%pip cache purge"
      ],
      "metadata": {
        "id": "vGxBixPM9wuJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test di supabase"
      ],
      "metadata": {
        "id": "lqCiFkvYy8sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test  di Supabase\n",
        "# lettura Direttive AI\n",
        "\n",
        "def carica_direttive(progetto=\"AI-Agent\"):\n",
        "    try:\n",
        "        # Interroga Supabase filtrando per il tuo progetto\n",
        "        response = supabase.table(\"direttive_ai\").select(\"*\").eq(\"progetto_nome\", progetto).execute()\n",
        "\n",
        "        if response.data:\n",
        "            print(f\"--- Direttive caricate per il progetto: {progetto} ---\")\n",
        "            for record in response.data:\n",
        "                print(f\"[{record['sezione']}]: {record['contenuto']}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Nessuna direttiva trovata per questo progetto.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Errore durante la lettura: {e}\")\n",
        "\n",
        "# Esegui il test\n",
        "carica_direttive()"
      ],
      "metadata": {
        "id": "_2GLY5rCy_v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3fe3a84"
      },
      "source": [
        "### 3. Gestione delle Istruzioni tramite Database SQLite\n",
        "\n",
        "Per scenari pi√π complessi, dove le istruzioni sono molteplici, dinamiche o devono essere associate a specifici contesti/tool, un database offre maggiore flessibilit√† e organizzazione rispetto a semplici file di testo. Qui useremo **SQLite**, un database leggero e basato su file, ideale per iniziare in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84523ea3"
      },
      "source": [
        "# Cella 3: SQLite Operazioni e Backup\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "# Nota: PATH_LAVORO e PATH_DRIVE sono ereditati dalla cella precedente\n",
        "\n",
        "print(\"--- 2. Esecuzione Operazioni Database ---\")\n",
        "\n",
        "def gestisci_database():\n",
        "    # 1. Connessione al database LOCALE (veloce e sicuro)\n",
        "    try:\n",
        "        conn = sqlite3.connect(PATH_LAVORO)\n",
        "        cursor = conn.cursor()\n",
        "        print(f\"‚úÖ Connesso al DB locale: {NOME_DB}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRORE Connessione: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # 2. Creazione Tabella (Schema)\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS instructions (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                name TEXT NOT NULL UNIQUE,\n",
        "                content TEXT NOT NULL,\n",
        "                description TEXT\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # 3. Inserimento Dati (Logica upsert/ignore)\n",
        "        istruzioni_da_inserire = [\n",
        "            ('persona_base', 'Sei un assistente AI neutrale e collaborativo. Rispondi sempre in italiano.', 'Prompt base'),\n",
        "            ('formato_codice', 'Presenta sempre il codice formattato correttamente.', 'Formattazione'),\n",
        "            ('evita_saluti', 'Evita saluti, vai dritto al punto.', 'Stile')\n",
        "        ]\n",
        "\n",
        "        changes_count = 0\n",
        "        for name, content, desc in istruzioni_da_inserire:\n",
        "            try:\n",
        "                # Usiamo INSERT OR IGNORE o gestiamo l'errore per evitare duplicati\n",
        "                cursor.execute(\"INSERT INTO instructions (name, content, description) VALUES (?, ?, ?)\",\n",
        "                               (name, content, desc))\n",
        "                print(f\"   ‚ûï Istruzione inserita: '{name}'\")\n",
        "                changes_count += 1\n",
        "            except sqlite3.IntegrityError:\n",
        "                # Se esiste gi√†, possiamo decidere se ignorare o aggiornare. Qui ignoriamo e avvisiamo.\n",
        "                # Se volessi aggiornare useresti: UPDATE instructions SET content = ? WHERE name = ?\n",
        "                pass\n",
        "                # print(f\"   (i) Istruzione '{name}' gi√† presente.\")\n",
        "\n",
        "        conn.commit()\n",
        "        print(f\"‚úÖ Modifiche salvate in locale ({changes_count} nuovi inserimenti).\")\n",
        "\n",
        "        # 4. Lettura e Controllo\n",
        "        print(\"\\n--- Anteprima Contenuto DB ---\")\n",
        "        df = pd.read_sql_query(\"SELECT name, description FROM instructions\", conn)\n",
        "        print(df)\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ERRORE durante le query: {e}\")\n",
        "        conn.rollback()\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "    # 5. SALVATAGGIO SU DRIVE (Cruciale)\n",
        "    # Sovrascriviamo il file su Drive con la versione appena modificata\n",
        "    try:\n",
        "        shutil.copy2(PATH_LAVORO, PATH_DRIVE)\n",
        "        print(f\"\\nüíæ BACKUP RIUSCITO: Database salvato su Google Drive.\")\n",
        "        print(f\"   Percorso: {PATH_DRIVE}\")\n",
        "        print(f\"   Ora: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERRORE BACKUP SU DRIVE: {e}\")\n",
        "        print(\"‚ö†Ô∏è Attenzione: i dati sono salvati solo nell'ambiente temporaneo di Colab!\")\n",
        "\n",
        "# Eseguiamo la funzione\n",
        "gestisci_database()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 4: Caricamento e Inizializzazione del Modello LLM\n",
        "\n",
        "Questa cella √® dedicata alla fase di caricamento e inizializzazione del modello di linguaggio (LLM) Gemma.\n",
        "\n",
        "1.  **Istanziazione:** La libreria `llama_cpp` viene impiegata per creare un'istanza dell'oggetto `Llama`.\n",
        "2.  **Localizzazione Risorsa:** Si definisce il percorso su Google Drive (`CARTELLA_MODELLI`) dove risiede il file del modello (`.gguf`).\n",
        "3.  **Ottimizzazione Hardware:** Il parametro `n_gpu_layers=-1` configura il modello per delegare la massima parte dei calcoli alla GPU, incrementando le prestazioni.\n",
        "4.  **Gestione Contesto:** `n_ctx` imposta la finestra di contesto, cio√® la quantit√† di testo che il modello pu√≤ \"ricordare\" per generare risposte coerenti.\n",
        "\n",
        "**Verifica Esito:** Un caricamento successo √® attestato da un messaggio di conferma. Eventuali errori indicano problemi di percorso o compatibilit√†, impedendo l'operativit√† del sistema AI.\n"
      ],
      "metadata": {
        "id": "JlInYn_zi1P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 4: Definizione Percorso e Caricamento del Modello\n",
        "print(\"--- 2. Caricamento Modello ---\")\n",
        "\n",
        "# 1. Creazione istanza Llama\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# 2. Definizione percorso modelli su Drive\n",
        "CARTELLA_MODELLI = \"/content/drive/MyDrive/LLM Models/\"\n",
        "NOME_FILE_GGUF = \"gemma-2-2b-it-Q8_0.gguf\"\n",
        "PERCORSO_MODELLO_COMPLETO = os.path.join(CARTELLA_MODELLI, NOME_FILE_GGUF)\n",
        "\n",
        "llm = None # Inizializza la variabile llm\n",
        "\n",
        "# Verifica l'esistenza del file e carica il modello\n",
        "if not os.path.exists(PERCORSO_MODELLO_COMPLETO):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"‚ùå ERRORE: Il file GGUF NON √® stato trovato al percorso:\")\n",
        "    print(f\"Percorso cercato: {PERCORSO_MODELLO_COMPLETO}\")\n",
        "    print(\"Controlla che il file GGUF e il nome siano corretti.\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    print(f\"‚úÖ File del modello trovato: {PERCORSO_MODELLO_COMPLETO}\")\n",
        "    try:\n",
        "        print(\"\\nCaricamento del modello in corso... (Questo √® il passo che richiede pi√π tempo: circa 2 minuti)\")\n",
        "        llm = Llama(\n",
        "            model_path=PERCORSO_MODELLO_COMPLETO,\n",
        "            n_gpu_layers=-1, # Offload completo sulla GPU\n",
        "            n_ctx=4096,\n",
        "            verbose=False\n",
        "        )\n",
        "        print(\"üéâ Modello Gemma caricato e pronto per l'inferenza!\")\n",
        "    except Exception as e:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(f\"‚ùå ERRORE GRAVE durante il caricamento del modello. Dettagli: {e}\")\n",
        "        print(\"Controlla la configurazione della GPU e la validit√† del file GGUF.\")\n",
        "        print(\"=\"*50)"
      ],
      "metadata": {
        "id": "5hE4egyXYU5F",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 5"
      ],
      "metadata": {
        "id": "RQ4cRcLdjBdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRFYKxRqWIrX"
      },
      "outputs": [],
      "source": [
        "# Cella 5: Definizione della funzione di Inferenza\n",
        "print(\"--- 3. Definizione Funzione ---\")\n",
        "\n",
        "def generate_response(llm_model, user_prompt, max_tokens=2024, temperature=0.7, stop_sequence=[\"<end_of_turn>\"]):\n",
        "    \"\"\"\n",
        "    Funzione riutilizzabile per generare risposte da un modello Gemma Instruct.\n",
        "    \"\"\"\n",
        "    if llm_model is None:\n",
        "        return \"Errore: Il modello LLM non √® stato caricato correttamente nella Cella 2.\"\n",
        "\n",
        "    # Formattazione specifica per Gemma Instruct\n",
        "    prompt_formattato = f\"<start_of_turn>user\\n{user_prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "    output = llm_model(\n",
        "        prompt_formattato,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stop=stop_sequence,\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    # Estrai il testo e rimuovi spazi extra\n",
        "    return output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "print(\"‚úÖ Funzione 'generate_response' definita. Pronto per la Cella 6.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cella 6"
      ],
      "metadata": {
        "id": "MuDjNn9VjExP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm1k46WyWFov"
      },
      "outputs": [],
      "source": [
        "# Cella 6: fai la domanda e ottieni la risposta\n",
        "print(\"--- 4. Esecuzione Test ---\")\n",
        "\n",
        "# Definisci la tua domanda qui\n",
        "PROMPT_UTENTE = \"Non mi hai risposto alla prima domanda: ricordi le domande che ti ho gi√† fatto? Se si, √® cambiato qualcosa nel mondo e voglio vedere se tu (un llm fermo ad una data) eri in grado di prevederlo\"\n",
        "\n",
        "print(f\"Domanda inviata a Gemma: {PROMPT_UTENTE}\")\n",
        "\n",
        "# Chiama la funzione\n",
        "risposta = generate_response(llm, PROMPT_UTENTE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA ---\")\n",
        "print(risposta)\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13fed9ca"
      },
      "source": [
        "### 7. Creazione di un file di istruzioni (esempio)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c2029e5"
      },
      "source": [
        "# Cella 7\n",
        "# Definisci il percorso e il nome del file di istruzioni\n",
        "FILE_ISTRUZIONI = \"istruzioni_personalizzate.txt\"\n",
        "\n",
        "# Contenuto delle istruzioni\n",
        "# Questo √® ci√≤ che il tuo modello \"legger√†\" prima del tuo prompt principale\n",
        "contenuto_istruzioni = (\n",
        "    \"Sei un assistente AI amichevole e collaborativo. \"\n",
        "    \"Rispondi sempre in italiano. \\n\"\n",
        "    \"Fornisci risposte dettagliate e utili, ma sii conciso quando possibile.\"\n",
        "    \"Presenta sempre il codice formattato correttamente con i blocchi di codice. \\n\"\n",
        "    \"Evita di aggiungere saluti o ringraziamenti.\"\n",
        "    \"Rispondi direttamente alla domanda dell'utente.\"\n",
        ")\n",
        "\n",
        "# Scrivi le istruzioni nel file\n",
        "with open(FILE_ISTRUZIONI, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(contenuto_istruzioni)\n",
        "\n",
        "print(f\"File '{FILE_ISTRUZIONI}' creato con successo.\\nContenuto:\\n{contenuto_istruzioni}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlTQ9aX6IU62"
      },
      "source": [
        "# cella 8:\n",
        "# Leggi le istruzioni dal file\n",
        "try:\n",
        "    with open(FILE_ISTRUZIONI, \"r\", encoding=\"utf-8\") as f:\n",
        "        istruzioni_da_file = f.read()\n",
        "    print(f\"Istruzioni lette dal file '{FILE_ISTRUZIONI}'.\")\n",
        "except FileNotFoundError:\n",
        "    istruzioni_da_file = \"\"\n",
        "    print(f\"‚ùå ERRORE: File di istruzioni '{FILE_ISTRUZIONI}' non trovato.\")\n",
        "\n",
        "# Prompt principale dell'utente\n",
        "PROMPT_UTENTE_AGGIUNTIVO = \"crea un programma in python per montare google drive\"\n",
        "\n",
        "# Combina le istruzioni con il prompt dell'utente\n",
        "# Puoi decidere come strutturare il prompt combinato.\n",
        "# Ad esempio, prima le istruzioni, poi la domanda specifica.\n",
        "PROMPT_FINALE = f\"{istruzioni_da_file.strip()}\\n\\nUtente: {PROMPT_UTENTE_AGGIUNTIVO}\"\n",
        "\n",
        "print(f\"\\nPrompt finale inviato a Gemma:\\n---\\n{PROMPT_FINALE}\\n---\")\n",
        "\n",
        "# Chiama la funzione con il nuovo prompt combinato\n",
        "risposta_con_istruzioni = generate_response(llm, PROMPT_FINALE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA CON ISTRUZIONI --- \")\n",
        "print(risposta_con_istruzioni)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# IMPORTANTE: Metti la chiusura della connessione alla fine del notebook\n",
        "# o quando sai che non dovrai pi√π accedere al DB in questa sessione,\n",
        "# altrimenti potresti avere errori se provi ad accedervi di nuovo.\n",
        "# conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewngbSspIRH3"
      },
      "source": [
        "# cella 8:\n",
        "# Leggi le istruzioni dal file\n",
        "try:\n",
        "    with open(FILE_ISTRUZIONI, \"r\", encoding=\"utf-8\") as f:\n",
        "        istruzioni_da_file = f.read()\n",
        "    print(f\"Istruzioni lette dal file '{FILE_ISTRUZIONI}'.\")\n",
        "except FileNotFoundError:\n",
        "    istruzioni_da_file = \"\"\n",
        "    print(f\"‚ùå ERRORE: File di istruzioni '{FILE_ISTRUZIONI}' non trovato.\")\n",
        "\n",
        "# Prompt principale dell'utente\n",
        "PROMPT_UTENTE_AGGIUNTIVO = \"spiegami che tool posso inserire con facilit√† in un Agent AI.\"\n",
        "\n",
        "# Combina le istruzioni con il prompt dell'utente\n",
        "# Puoi decidere come strutturare il prompt combinato.\n",
        "# Ad esempio, prima le istruzioni, poi la domanda specifica.\n",
        "PROMPT_FINALE = f\"{istruzioni_da_file.strip()}\\n\\nUtente: {PROMPT_UTENTE_AGGIUNTIVO}\"\n",
        "\n",
        "print(f\"\\nPrompt finale inviato a Gemma:\\n---\\n{PROMPT_FINALE}\\n---\")\n",
        "\n",
        "# Chiama la funzione con il nuovo prompt combinato\n",
        "risposta_con_istruzioni = generate_response(llm, PROMPT_FINALE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA CON ISTRUZIONI --- \")\n",
        "print(risposta_con_istruzioni)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# IMPORTANTE: Metti la chiusura della connessione alla fine del notebook\n",
        "# o quando sai che non dovrai pi√π accedere al DB in questa sessione,\n",
        "# altrimenti potresti avere errori se provi ad accedervi di nuovo.\n",
        "# conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "077935ad"
      },
      "source": [
        "### 8. Lettura del file e integrazione nel prompt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fc547fa"
      },
      "source": [
        "# cella 8:\n",
        "# Leggi le istruzioni dal file\n",
        "try:\n",
        "    with open(FILE_ISTRUZIONI, \"r\", encoding=\"utf-8\") as f:\n",
        "        istruzioni_da_file = f.read()\n",
        "    print(f\"Istruzioni lette dal file '{FILE_ISTRUZIONI}'.\")\n",
        "except FileNotFoundError:\n",
        "    istruzioni_da_file = \"\"\n",
        "    print(f\"‚ùå ERRORE: File di istruzioni '{FILE_ISTRUZIONI}' non trovato.\")\n",
        "\n",
        "# Prompt principale dell'utente\n",
        "PROMPT_UTENTE_AGGIUNTIVO = \"spiegami che tool posso inserire con facilit√† in un Agent AI.\"\n",
        "\n",
        "# Combina le istruzioni con il prompt dell'utente\n",
        "# Puoi decidere come strutturare il prompt combinato.\n",
        "# Ad esempio, prima le istruzioni, poi la domanda specifica.\n",
        "PROMPT_FINALE = f\"{istruzioni_da_file.strip()}\\n\\nUtente: {PROMPT_UTENTE_AGGIUNTIVO}\"\n",
        "\n",
        "print(f\"\\nPrompt finale inviato a Gemma:\\n---\\n{PROMPT_FINALE}\\n---\")\n",
        "\n",
        "# Chiama la funzione con il nuovo prompt combinato\n",
        "risposta_con_istruzioni = generate_response(llm, PROMPT_FINALE)\n",
        "\n",
        "# Stampa il risultato\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"--- RISPOSTA GENERATA CON ISTRUZIONI --- \")\n",
        "print(risposta_con_istruzioni)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# IMPORTANTE: Metti la chiusura della connessione alla fine del notebook\n",
        "# o quando sai che non dovrai pi√π accedere al DB in questa sessione,\n",
        "# altrimenti potresti avere errori se provi ad accedervi di nuovo.\n",
        "# conn.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a5f911b"
      },
      "source": [
        "### 9. Integrazione delle Istruzioni dal Database e Nuovo Ciclo di Chat\n",
        "Questa sezione mostra come recuperare le istruzioni dal database SQLite e integrarle in un prompt per una conversazione interattiva con l'agente AI. Questo √® un passo avanti rispetto alla gestione statica delle istruzioni da file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90c950a3"
      },
      "source": [
        "# Cella 9: Integrazione Istruzioni dal DB in un loop di chat\n",
        "\n",
        "# Riutilizziamo la funzione definita in Cella 6 per recuperare tutte le istruzioni\n",
        "# Assicurati che 'conn' e 'cursor' siano ancora aperti dalla Cella 6. Se hai chiuso la connessione, riaprila qui.\n",
        "\n",
        "import sqlite3 # Ensure sqlite3 is imported in this cell for robustness\n",
        "\n",
        "# Fix: sqlite3.Connection objects do not have a 'closed' attribute.\n",
        "# To handle the case where 'conn' might be closed from a previous cell\n",
        "# (as `conn.close()` was called in cell 1fc547fa), we should always re-establish the connection.\n",
        "# We'll explicitly close any existing connection before opening a new one,\n",
        "# which is good practice to ensure a clean state, even if already closed or unusable.\n",
        "if 'conn' in globals() and isinstance(globals().get('conn'), sqlite3.Connection):\n",
        "    try:\n",
        "        globals()['conn'].close()\n",
        "        print(\"Existing database connection explicitly closed before re-opening.\")\n",
        "    except Exception as e:\n",
        "        # This catch is mostly for cases where 'conn' exists but is somehow corrupted\n",
        "        print(f\"Warning: Could not close existing connection cleanly: {e}\")\n",
        "    conn = None # Reset conn to ensure a new connection is made\n",
        "\n",
        "print(\"Riapro la connessione al database...\")\n",
        "try:\n",
        "    conn = sqlite3.connect(PERCORSO_DB_COMPLETO)\n",
        "    cursor = conn.cursor()\n",
        "    print(\"‚úÖ Connessione al database SQLite riaperta.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå ERRORE: Impossibile riaprire la connessione al database. {e}\")\n",
        "\n",
        "def get_all_instructions_content(cursor_obj):\n",
        "    cursor_obj.execute(\"SELECT content FROM instructions ORDER BY id\")\n",
        "    return \"\\n\".join([row[0] for row in cursor_obj.fetchall()])\n",
        "\n",
        "# Recupera tutte le istruzioni dal database\n",
        "db_instructions = get_all_instructions_content(cursor)\n",
        "\n",
        "print(\"--- Istruzioni dal Database ---\")\n",
        "print(db_instructions)\n",
        "print(\"-------------------------------\")\n",
        "\n",
        "# Iniziamo una storia di conversazione\n",
        "conversation_history = []\n",
        "\n",
        "# Funzione per generare una risposta combinando istruzioni e storia\n",
        "def generate_chat_response(llm_model, user_input, history, system_instructions, max_tokens=2024, temperature=0.7, stop_sequence=[\"<end_of_turn>\"]):\n",
        "    # Costruisci il prompt combinando istruzioni, storia e input utente\n",
        "    full_prompt = f\"{system_instructions.strip()}\\n\\n\"\n",
        "\n",
        "    for role, message in history:\n",
        "        if role == \"user\":\n",
        "            full_prompt += f\"<start_of_turn>user\\n{message}<end_of_turn>\\n\"\n",
        "        elif role == \"model\":\n",
        "            full_prompt += f\"<start_of_turn>model\\n{message}<end_of_turn>\\n\"\n",
        "\n",
        "    full_prompt += f\"<start_of_turn>user\\n{user_input}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
        "\n",
        "    print(f\"\\nDEBUG: Prompt completo inviato al modello:\\n---\\n{full_prompt}\\n---\\n\")\n",
        "\n",
        "    output = llm_model(\n",
        "        full_prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        stop=stop_sequence,\n",
        "        echo=False\n",
        "    )\n",
        "    return output[\"choices\"][0][\"text\"].strip()\n",
        "\n",
        "\n",
        "print(\"\\n--- Inizia la conversazione (digita 'esci' per terminare) ---\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Utente: \")\n",
        "    if user_input.lower() == 'esci':\n",
        "        break\n",
        "\n",
        "    response = generate_chat_response(llm, user_input, conversation_history, db_instructions)\n",
        "\n",
        "    print(f\"Agente: {response}\")\n",
        "\n",
        "    # Aggiungi la conversazione alla storia\n",
        "    conversation_history.append((\"user\", user_input))\n",
        "    conversation_history.append((\"model\", response))\n",
        "\n",
        "print(\"\\n--- Conversazione terminata ---\")\n",
        "\n",
        "# √à buona pratica chiudere la connessione al DB quando non serve pi√π\n",
        "# Fix: sqlite3.Connection objects do not have a 'closed' attribute.\n",
        "# A simpler check for sqlite3 is to see if 'conn' exists and is a connection object.\n",
        "if 'conn' in globals() and isinstance(globals().get('conn'), sqlite3.Connection):\n",
        "    try:\n",
        "        globals()['conn'].close()\n",
        "        print(\"Connessione al database chiusa.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not close connection during final cleanup: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}